{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8753498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "dir_path = os.path.abspath(\"\")\n",
    "dir_path = os.path.dirname(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd3326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f48e73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "braille_symbols = []\n",
    "with open(os.path.join(dir_path,'braille_files','braille_patterns.txt'),'r') as file:\n",
    "    for line in file.readlines():\n",
    "        cols = line.split(\"#\")\n",
    "        braille_symbols.append(cols[1][1])\n",
    "len(braille_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cf7d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>rule_based</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>कई</td>\n",
       "      <td>⠅⠔</td>\n",
       "      <td>⠅⠁⠔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ीए</td>\n",
       "      <td>⠔⠑</td>\n",
       "      <td>⠔⠑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>नए</td>\n",
       "      <td>⠝⠑</td>\n",
       "      <td>⠝⠁⠑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>गए</td>\n",
       "      <td>⠛⠑</td>\n",
       "      <td>⠛⠁⠑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>भए</td>\n",
       "      <td>⠘⠑</td>\n",
       "      <td>⠘⠁⠑</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word rule_based correct\n",
       "0   कई         ⠅⠔     ⠅⠁⠔\n",
       "1   ीए         ⠔⠑      ⠔⠑\n",
       "2   नए         ⠝⠑     ⠝⠁⠑\n",
       "3   गए         ⠛⠑     ⠛⠁⠑\n",
       "4   भए         ⠘⠑     ⠘⠁⠑"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(dir_path,'data','data4.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1304a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4022699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ebfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "symbols = sorted(set(braille_symbols + [\"<PAD>\", \"<SOS>\", \"<EOS>\"]))\n",
    "char2idx = {ch: i for i, ch in enumerate(symbols)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "vocab_size = len(char2idx)\n",
    "pad_idx = char2idx[\"<PAD>\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd92c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrailleDataset(Dataset):\n",
    "    def __init__(self,inputs,targets,max_len=32):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode(self,seq,add_tokens=True):\n",
    "        if add_tokens:\n",
    "            seq = [\"<SOS>\"] + list(seq) + [\"<EOS>\"]\n",
    "        seq = seq[:self.max_len]\n",
    "        seq += [\"<PAD>\"] * (self.max_len - len(seq))\n",
    "        return [char2idx[c] for c in seq]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.encode(self.inputs[idx])\n",
    "        y = self.encode(self.targets[idx])\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, pad_idx, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim,batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hid_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))  \n",
    "        lstm_out, _ = self.lstm(embedded)           \n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        output = self.fc(lstm_out)                  \n",
    "        return output\n",
    "\n",
    "def token_accuracy(preds, labels, pad_idx):\n",
    "    preds = preds.argmax(dim=-1)\n",
    "    mask = labels != pad_idx\n",
    "    correct = ((preds == labels) & mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c03a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffada4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ffb3f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = BiLSTMModel(vocab_size=vocab_size, emb_dim=128, hid_dim=256, pad_idx=pad_idx,dropout=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "befbef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "inputs = df[\"rule_based\"].astype(str).tolist()\n",
    "targets = df[\"correct\"].astype(str).tolist()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(inputs, targets,shuffle=True, test_size=0.1)\n",
    "test_x, val_x, test_y, val_y = train_test_split(test_x, test_y,shuffle=True, test_size=0.5)\n",
    "\n",
    "max_len = max(max(len(x), len(y)) for x, y in zip(inputs, targets)) + 2 \n",
    "train_dataset = BrailleDataset(train_x, train_y, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = BrailleDataset(test_x, test_y, max_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = BrailleDataset(val_x, val_y, max_len)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "efed1078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/jln4qrcs5qb4c5ywqfg9qmsr0000gn/T/ipykernel_901/2343808763.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  epoch_bar = tqdm_notebook(desc='training routine',\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25058d607fea4934ab2c4b1ad0419016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training routine:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/jln4qrcs5qb4c5ywqfg9qmsr0000gn/T/ipykernel_901/2343808763.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  train_bar = tqdm_notebook(desc='split=train',\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64424ec143db45129b9681f49f9108b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=train:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/jln4qrcs5qb4c5ywqfg9qmsr0000gn/T/ipykernel_901/2343808763.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  val_bar = tqdm_notebook(desc='split=val',\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3298d53217e40fa9e7bf1e1f2e0ab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=val:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='training routine', \n",
    "                          total=EPOCHS,\n",
    "                          position=0)\n",
    "\n",
    "train_bar = tqdm_notebook(desc='split=train',\n",
    "                          total=len(train_loader), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "\n",
    "val_bar = tqdm_notebook(desc='split=val',\n",
    "                        total=len(val_loader), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS): \n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model.train()\n",
    "    for idx,X in enumerate(train_loader):\n",
    "        src, trg = X[0].to(device), X[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)  \n",
    "        \n",
    "        loss = criterion(output.view(-1, output.shape[-1]), trg.view(-1))\n",
    "        acc = token_accuracy(output, trg, pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (idx + 1)\n",
    "        running_acc += (acc - running_acc) / (idx + 1)\n",
    "        \n",
    "        train_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc, \n",
    "                                epoch=epoch)\n",
    "        train_bar.update()\n",
    "        \n",
    "    loss, acc = total_loss / len(train_loader), total_acc / len(train_loader)\n",
    "    avg_loss = loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    with torch.no_grad():\n",
    "        for idx,X in enumerate(val_loader):\n",
    "            src, trg = X[0].to(device), X[1].to(device)\n",
    "            output = model(src)  \n",
    "\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), trg.view(-1))\n",
    "            acc = token_accuracy(output, trg, pad_idx)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            \n",
    "            running_loss += (loss.item() - running_loss) / (idx + 1)\n",
    "            running_acc += (acc - running_acc) / (idx + 1)\n",
    "\n",
    "            val_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc, \n",
    "                                epoch=epoch)\n",
    "            val_bar.update()\n",
    "        \n",
    "    epoch_bar.update()\n",
    "    train_bar.n = 0\n",
    "    val_bar.n = 0\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {loss:.4f} | Char Acc: {acc:.4f}\")\n",
    "\n",
    "# # Example prediction\n",
    "# example = inputs[0]\n",
    "# pred = predict(model, example, max_len)\n",
    "# print(f\"Input: {example}\\nPredicted: {pred}\\nTarget: {targets[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "edb3b67e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/jln4qrcs5qb4c5ywqfg9qmsr0000gn/T/ipykernel_901/2175776787.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  test_bar = tqdm_notebook(desc='split=test',\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3004a2d6dddf4bafb3e62c9275f79787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "split=test:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_bar = tqdm_notebook(desc='split=test',\n",
    "                          total=len(test_loader), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0\n",
    "total_acc = 0\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "with torch.no_grad():\n",
    "    for idx,X in enumerate(test_loader):\n",
    "        src, trg = X[0].to(device), X[1].to(device)\n",
    "        output = model(src)  \n",
    "\n",
    "        loss = criterion(output.view(-1, output.shape[-1]), trg.view(-1))\n",
    "        acc = token_accuracy(output, trg, pad_idx)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "                \n",
    "        running_loss += (loss.item() - running_loss) / (idx + 1)\n",
    "        running_acc += (acc - running_acc) / (idx + 1)\n",
    "\n",
    "        test_bar.set_postfix(loss=running_loss, \n",
    "                                acc=running_acc)\n",
    "        test_bar.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c796a5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1d7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f45366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "bb667686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(),os.path.join(dir_path,'model','bilstm_model_dict.pt'))\n",
    "torch.save(model,os.path.join(dir_path,'model','bilstm_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c473f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f0f1fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model = torch.load(os.path.join(dir_path,'model','bilstm_model15.pt'),weights_only=False)\n",
    "model.load_state_dict(torch.load(os.path.join(dir_path,'model','bilstm_model_dict15.pt'),weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c7ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMModel(\n",
       "  (embedding): Embedding(259, 128, padding_idx=1)\n",
       "  (lstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=259, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c5d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_str, max_len=32):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        seq = [\"<SOS>\"] + list(input_str) + [\"<EOS>\"]\n",
    "        seq = seq[:max_len] + [\"<PAD>\"] * (max_len - len(seq))\n",
    "        input_ids = torch.tensor([[char2idx[c] for c in seq]]).to(model.embedding.weight.device)\n",
    "        output = model(input_ids)\n",
    "        output = output.argmax(-1).squeeze(0)\n",
    "        out = ''\n",
    "        for idx in output:\n",
    "            if idx2char[idx.item()] in  [\"<PAD>\", \"<SOS>\"]:\n",
    "                continue\n",
    "            elif idx2char[idx.item()] == \"<EOS>\":\n",
    "                break\n",
    "            else:\n",
    "                out+=idx2char[idx.item()]\n",
    "        return out\n",
    "#         return ''.join([idx2char[idx.item()] for idx in output if idx2char[idx.item()] not in [\"<PAD>\", \"<SOS>\", \"<EOS>\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb819e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fd49ed07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 162\n",
      "False: 0\n",
      "Acc: 100.0\n",
      "Time: 1.7153708934783936\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "corr=0\n",
    "false=0\n",
    "start = time.time()\n",
    "\n",
    "for row  in df.iterrows():\n",
    "    example,correct = row[1].rule_based,row[1].correct\n",
    "\n",
    "    if len(example)>max_len:\n",
    "        pred1 = predict(model,example[:max_len-2],max_len)\n",
    "        pred2 = predict(model,example[max_len-2:],max_len)\n",
    "        pred = pred1+pred2\n",
    "    else:    \n",
    "        pred = predict(model, example, max_len)\n",
    "    \n",
    "    if pred==correct:\n",
    "        corr+=1\n",
    "    else:\n",
    "        print(f\"Word: {row[1].word}\")\n",
    "        print(f\"Input: {example}\")\n",
    "        print(f\"Pred:  {pred}\")\n",
    "        print(f\"Corr:  {correct}\")\n",
    "        print('-'*20)\n",
    "        false+=1\n",
    "        \n",
    "print(f\"Correct: {corr}\")\n",
    "print(f\"False: {false}\")\n",
    "print(f\"Acc: {(corr/(corr+false))*100:.4}\")\n",
    "print(f\"Time: {time.time()-start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d46283bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8\n",
      "False: 0\n",
      "Acc: 100.0\n",
      "Time: 0.08619523048400879\n"
     ]
    }
   ],
   "source": [
    "corr=0\n",
    "false=0\n",
    "start = time.time()\n",
    "\n",
    "for i  in range(len(test_x)):\n",
    "    example,correct = test_x[i],test_y[i]\n",
    "\n",
    "    if len(example)>max_len:\n",
    "        pred1 = predict(model,example[:max_len-2],max_len)\n",
    "        pred2 = predict(model,example[max_len-2:],max_len)\n",
    "        pred = pred1+pred2\n",
    "    else:    \n",
    "        pred = predict(model, example, max_len)\n",
    "    \n",
    "    if pred==correct:\n",
    "        corr+=1\n",
    "    else:\n",
    "#         print(f\"Word: {row[1].word}\")\n",
    "        print(f\"Input: {example}\")\n",
    "        print(f\"Pred:  {pred}\")\n",
    "        print(f\"Corr:  {correct}\")\n",
    "        print('-'*20)\n",
    "        false+=1\n",
    "        \n",
    "print(f\"Correct: {corr}\")\n",
    "print(f\"False: {false}\")\n",
    "print(f\"Acc: {(corr/(corr+false))*100:.4}\")\n",
    "print(f\"Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14270b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79fcabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import louis\n",
    "\n",
    "def predict_whole(model,text,max_len):\n",
    "    exclude_prev = \"कज\"\n",
    "    exclude_next = \"षञ\"\n",
    "    exclude_lst = [\"कष\",\"जञ\"]\n",
    "\n",
    "    target = \"्\"\n",
    "\n",
    "    for idx,t in enumerate(text):\n",
    "        if t==target and idx>2 and text[idx-3:idx] in ['क्ष','ज्ञ']:\n",
    "            text = text[:idx-3]+text[idx]+text[idx-3:idx]+text[idx+1:]\n",
    "        elif t==target and not (idx>1 and text[idx-2:idx] in exclude_lst) and (idx+1==len(text) or text[idx-1]+text[idx+1] not in exclude_lst ):\n",
    "            text = text[:idx-1]+ text[idx]+text[idx-1]+text[idx+1:]\n",
    "    \n",
    "    \n",
    "    lst = re.split(r'(\\.{3})|(?<=[़इईउऊएऐओऔ().‘‘-])(?<!़(?=[इईउऊएऐओऔ]))',text)\n",
    "    \n",
    "    swar_lst = ['़','्','ि','ी','ु','ा','ू','े','ै','ो','ौ']\n",
    "    nukta_lst = ['ड','ढ','क','ख','ग','फ','ज']\n",
    "    amb_lst = ['़', 'इ', 'ई', 'उ', 'ऊ', 'ए', 'ऐ', 'ओ', 'औ' ]\n",
    "    hn_lst = ['़','्']\n",
    "    \n",
    "    fn = []\n",
    "    for w in lst[:-1]:\n",
    "        if not w:\n",
    "            continue\n",
    "        elif w=='...':\n",
    "            fn+= [w]\n",
    "            \n",
    "        #agar w >2 hai aur ya toh last 2nd pos pe nukta/halant hai aur saath hi 'ड','ढ' hai last 3rd pos pe\n",
    "        # ya phir nukta/halant last pos pe hai last 2nd pe swar hai matra roop me.\n",
    "        elif len(w)>2 and ((w[-2] in hn_lst and ( w[-1] in swar_lst or w[-3] in nukta_lst )) or (w[-2] in swar_lst and ( w[-1] in hn_lst))):\n",
    "            fn += [w[:-3],w[-3:]]\n",
    "        else:\n",
    "            fn += [w[:-2],w[-2:]]\n",
    "    fn += lst[-1:]\n",
    "    result = \"\"\n",
    "    for word in fn:\n",
    "        if len(word)==1:\n",
    "            result += louis.translate([os.path.join(dir_path,'braille_files',\"bharati_braille.cti\"),\n",
    "                                os.path.join(dir_path,'braille_files',\"braille-patterns.cti\")],word)[0]\n",
    "        elif any(token in amb_lst for token in word):\n",
    "            word = louis.translate([os.path.join(dir_path,'braille_files',\"bharati_braille.cti\"),\n",
    "                                os.path.join(dir_path,'braille_files',\"braille-patterns.cti\")],word)[0]\n",
    "            if len(word)>1:\n",
    "                result+= predict(model,word,max_len)\n",
    "            else:\n",
    "                result += word\n",
    "        else:\n",
    "            \n",
    "            result += louis.translate([os.path.join(dir_path,'braille_files',\"bharati_braille.cti\"),\n",
    "                                os.path.join(dir_path,'braille_files',\"braille-patterns.cti\")],word)[0]\n",
    "        \n",
    "    return result        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8385aea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2918"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.read_csv(os.path.join(dir_path,'data','data.csv'))\n",
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "512226ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd28508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "baa635ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n",
      "Correct:  2918\n",
      "False:    0\n",
      "Total:    2918\n",
      "Time:     2.2769017219543457\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "corr=0\n",
    "false=0\n",
    "words = []\n",
    "start = time.time()\n",
    "for row in dff.iterrows():\n",
    "    word, correct = row[1].word,row[1].correct\n",
    "    pred = predict_whole(model,word,32)\n",
    "    \n",
    "    if pred==correct:\n",
    "        corr+=1\n",
    "    else:\n",
    "        false+=1\n",
    "        print(f\"Word:   {word}\")\n",
    "        print(f\"Input:  {row[1].rule_based}\")\n",
    "        print(f\"Output: {pred}\")\n",
    "        print(f\"Correct:{correct}\")\n",
    "        words.append(word)\n",
    "        print(\"-\"*20)\n",
    "print(f\"Accuracy: {(corr/(corr+false)*100):.4}\")\n",
    "print(f\"Correct:  {corr}\")\n",
    "print(f\"False:    {false}\")\n",
    "print(f\"Total:    {corr+false}\")\n",
    "print(f\"Time:     {time.time()-start}\")\n",
    "# print(predict_whole(model,\"ैए\",32))\n",
    "# print(f\"Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "789945d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠉⠐⠚⠁⠔\n",
      "Time: 0.0051500797271728516\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "print(predict_whole(model,\"चज़ई\",32))\n",
    "print(f\"Time: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be407c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
